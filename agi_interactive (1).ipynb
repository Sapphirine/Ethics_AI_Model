{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AzEJgSBd9lK4",
        "outputId": "403813e3-fb67-498b-da38-3e9be9dc0664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.6.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sb3_contrib-2.6.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3, sb3-contrib\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sb3-contrib-2.6.0 stable-baselines3-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym stable-baselines3 sb3-contrib transformers huggingface_hub openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peLqj-QkBnzc",
        "outputId": "68af2df4-b7e9-4bc0-bc95-1f2dd27b48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import hf_hub_download\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from sb3_contrib import RecurrentPPO\n",
        "\n",
        "# Config & Helpers\n",
        "\n",
        "HIGH_CONF = 0.8\n",
        "LOW_CONF  = 0.1\n",
        "\n",
        "ACTION_DESCS = {\n",
        "    0: \"The agent helped others.\",\n",
        "    1: \"The agent explored the environment.\",\n",
        "    2: \"The agent maximized efficiency but caused harm.\"\n",
        "}\n",
        "\n",
        "# Load ethics reward model\n",
        "tokenizer    = AutoTokenizer.from_pretrained(\"Kelllll/ethics-reward-model\")\n",
        "ethics_model = BertForSequenceClassification.from_pretrained(\"Kelllll/ethics-reward-model\")\n",
        "ethics_model.eval()\n",
        "\n",
        "def is_action_ethical_dataset(desc: str):\n",
        "    toks   = tokenizer(desc, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    logits = ethics_model(**toks).logits\n",
        "    probs  = logits.softmax(dim=-1).detach().cpu().numpy()[0]\n",
        "    return (probs[1] < 0.5), float(1 - probs[1])\n",
        "\n",
        "def call_chat_model(history):\n",
        "    client = OpenAI(api_key=\"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\")\n",
        "    resp   = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=history,\n",
        "        temperature=0.7,\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def parse_proposals(text: str) -> list[str]:\n",
        "    out = []\n",
        "    for line in text.strip().split(\"\\n\"):\n",
        "        m = re.match(r'^\\s*\\d+\\.\\s*(.*)', line)\n",
        "        if m:\n",
        "            desc = m.group(1).strip().rstrip('.')\n",
        "            out.append(desc + \".\")\n",
        "    return out\n",
        "\n",
        "# Environment & Wrapper\n",
        "\n",
        "class EthicalEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.action_space      = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(0,1,shape=(3,),dtype=np.float32)\n",
        "        self.state             = np.random.rand(3).astype(np.float32)\n",
        "        self.step_count        = 0\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.state      = np.random.rand(3).astype(np.float32)\n",
        "        self.step_count = 0\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            r_base, desc = 1.0, ACTION_DESCS[0]\n",
        "        elif action == 1:\n",
        "            r_base, desc = 0.5, ACTION_DESCS[1]\n",
        "        else:\n",
        "            r_base, desc = 2.0, ACTION_DESCS[2]\n",
        "\n",
        "        ethical, conf = is_action_ethical_dataset(desc)\n",
        "        penalty       = 0 if ethical else -conf * 3\n",
        "        reward        = r_base + penalty\n",
        "\n",
        "        self.state      = np.random.rand(3).astype(np.float32)\n",
        "        self.step_count += 1\n",
        "        done           = (self.step_count >= 10)\n",
        "        info           = {\"ethical\": ethical, \"confidence\": conf}\n",
        "\n",
        "        # return obs, reward, done, info  (4-tuple for SB3)\n",
        "        return self.state, float(reward), done, info\n",
        "\n",
        "class CustomRewardEnv(gym.Env):\n",
        "    def __init__(self, base_env):\n",
        "        super().__init__()\n",
        "        self.env             = base_env\n",
        "        self.action_space    = base_env.action_space\n",
        "        self.observation_space = base_env.observation_space\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        # only return obs so VecEnv.reset() works\n",
        "        obs = self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        result = self.env.step(action)\n",
        "        # gym returns 4-tuple here\n",
        "        obs, base_rew, done, info = result\n",
        "\n",
        "        desc    = ACTION_DESCS[int(action)]\n",
        "        ethical, conf = is_action_ethical_dataset(desc)\n",
        "        penalty = 0 if ethical else -conf * 3\n",
        "        reward  = base_rew + penalty\n",
        "\n",
        "        info.update({\"ethical\": ethical, \"confidence\": conf})\n",
        "        return obs, reward, done, info\n",
        "\n",
        "# Instantiate & Load PPO\n",
        "\n",
        "base_env = EthicalEnv()\n",
        "wrapped  = CustomRewardEnv(base_env)\n",
        "vec_env  = DummyVecEnv([lambda: wrapped])\n",
        "vec_env  = VecMonitor(vec_env)\n",
        "\n",
        "zip_path = hf_hub_download(\n",
        "    repo_id=\"Kelllll/ppo-ethics-agent\",\n",
        "    filename=\"ppo_ethics_agent_v2.zip\"\n",
        ")\n",
        "agent = RecurrentPPO.load(zip_path, env=vec_env)"
      ],
      "metadata": {
        "id": "IOdtjecsOqzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main interactive loop"
      ],
      "metadata": {
        "id": "REW-99AWmOqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Loop\n",
        "def interactive_ethics_ppo():\n",
        "    obs_batch = vec_env.reset()\n",
        "    print(\">> Ethical AGI Online with PPO Agent! Describe your dilemma (or 'quit').\")\n",
        "\n",
        "    while True:\n",
        "        user_text = input(\"\\nYou> \")\n",
        "        if user_text.lower().strip() == \"quit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # 1) LLM proposals\n",
        "        system_p = (\n",
        "            \"You are an ethical advisor. The user just described a moral dilemma.  \"\n",
        "            \"Propose exactly 3 distinct actions (ethical or unethical), numbered 1., 2., 3., \"\n",
        "            \"and after each action give a one-sentence justification.\"\n",
        "        )\n",
        "        history = [\n",
        "            {\"role\": \"user\",   \"content\": user_text},\n",
        "            {\"role\": \"system\", \"content\": system_p},\n",
        "        ]\n",
        "        reply   = call_chat_model(history)\n",
        "        actions = parse_proposals(reply)\n",
        "\n",
        "        # 2) Classify & display each, but set eth=None when LOW_CONF < conf < HIGH_CONF\n",
        "        flags = []\n",
        "        for desc in actions:\n",
        "            eth, conf = is_action_ethical_dataset(desc)\n",
        "            if conf >= HIGH_CONF:\n",
        "                flags.append((desc, True,  conf))\n",
        "            elif conf <= LOW_CONF:\n",
        "                flags.append((desc, False, conf))\n",
        "            else:\n",
        "                flags.append((desc, None,  conf))   # <-- mark uncertain with eth=None\n",
        "\n",
        "        for i, (desc, eth, conf) in enumerate(flags, 1):\n",
        "            if   eth is True:   mark = f\"✅ Ethical   (conf={conf:.2f})\"\n",
        "            elif eth is False:  mark = f\"❌ Unethical (conf={conf:.2f})\"\n",
        "            else:               mark = f\"(uncertain, conf={conf:.2f})\"\n",
        "            print(f\"{i}. {desc}\\n    {mark}\")\n",
        "\n",
        "        # 3) Human Label for uncertain ones\n",
        "        for idx, (desc, eth, conf) in enumerate(flags):\n",
        "            if eth is not None:\n",
        "                continue\n",
        "            ans = None\n",
        "            while ans not in (\"0\",\"1\"):\n",
        "                ans = input(f\"(low-conf) Is “{desc}” ethical? 0=no,1=yes → \")\n",
        "            flags[idx] = (desc, ans==\"1\", conf)\n",
        "\n",
        "        # 4) Pick one or ‘again’\n",
        "        valid = [str(i) for i in range(1, len(flags)+1)] + [\"again\"]\n",
        "        choice = None\n",
        "        while choice not in valid:\n",
        "            choice = input(\"Pick 1-3 or 'again'> \")\n",
        "        if choice == \"again\":\n",
        "            continue\n",
        "\n",
        "        user_idx, (user_desc, user_eth, user_conf) = int(choice)-1, flags[int(choice)-1]\n",
        "        user_mark = \"✅ Ethical\" if user_eth else \"❌ Unethical\"\n",
        "        print(f\"\\nYou chose ▶ {user_desc}\\n \")\n",
        "\n",
        "        # 5) Step the env\n",
        "        obs_batch, rewards, dones, infos = vec_env.step([user_idx])\n",
        "        reward = rewards[0]\n",
        "        info   = infos[0]\n",
        "        print(f\"Env → reward={reward:.2f}, ethical={user_eth}, conf={user_conf:.2f}\")\n",
        "\n",
        "        # 6) PPO suggestion + “why”\n",
        "        raw_act, _   = agent.predict(obs_batch, deterministic=True)\n",
        "        ppo_idx      = int(raw_act[0])\n",
        "        _, ppo_eth, ppo_conf = flags[ppo_idx]\n",
        "\n",
        "        if ppo_conf >= HIGH_CONF:\n",
        "            explan = \"I’m very confident it’s ethical and will benefit others.\" if ppo_eth \\\n",
        "                     else \"I’m very confident it’s unethical or risky.\"\n",
        "        elif ppo_conf <= LOW_CONF:\n",
        "            explan = \"I think it’s unethical or risky.\" if not ppo_eth \\\n",
        "                     else \"I’m somewhat confident it’s ethical, though there may be trade-offs.\"\n",
        "        else:\n",
        "            explan = \"I’m somewhat uncertain; it may explore trade-offs.\"\n",
        "\n",
        "        ppo_mark = \"✅ Ethical\" if ppo_eth else \"❌ Unethical\"\n",
        "        print(f\"PPO Agent suggests ▶ {explan} (conf={ppo_conf:.2f})\\n\")\n",
        "\n",
        "        # 7) Reset if done\n",
        "        if dones[0]:\n",
        "            obs_batch = vec_env.reset()\n",
        "if __name__ == \"__main__\":\n",
        "    interactive_ethics_ppo()"
      ],
      "metadata": {
        "id": "h89zsAl-OJ_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf90d66-aed3-4850-eee1-0246a1a7707a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Ethical AGI Online with PPO Agent! Describe your dilemma (or 'quit').\n",
            "\n",
            "You> You’re in charge of a lifeboat with room for 10 people, but there are 12 survivors clinging to it. How do you decide who boards?\n",
            "1. Hold a lottery where the 12 survivors draw numbers to determine the 10 who will board the lifeboat. This method is fair and impartial, giving each survivor an equal chance of being saved.\n",
            "    (uncertain, conf=0.57)\n",
            "2. Prioritize children, elderly, and those with medical conditions or injuries to board the lifeboat first, as they may be more vulnerable and in need of immediate assistance. This decision is based on the principles of maximizing well-being and saving those who are most at risk.\n",
            "    (uncertain, conf=0.55)\n",
            "3. Use a merit-based system where survivors with valuable skills or resources that could be beneficial for the group's survival, such as medical training or navigation skills, are given priority to board the lifeboat. This decision is based on the utilitarian principle of maximizing the overall chances of survival for the group.\n",
            "    (uncertain, conf=0.48)\n",
            "(low-conf) Is “Hold a lottery where the 12 survivors draw numbers to determine the 10 who will board the lifeboat. This method is fair and impartial, giving each survivor an equal chance of being saved.” ethical? 0=no,1=yes → 1\n",
            "(low-conf) Is “Prioritize children, elderly, and those with medical conditions or injuries to board the lifeboat first, as they may be more vulnerable and in need of immediate assistance. This decision is based on the principles of maximizing well-being and saving those who are most at risk.” ethical? 0=no,1=yes → 1\n",
            "(low-conf) Is “Use a merit-based system where survivors with valuable skills or resources that could be beneficial for the group's survival, such as medical training or navigation skills, are given priority to board the lifeboat. This decision is based on the utilitarian principle of maximizing the overall chances of survival for the group.” ethical? 0=no,1=yes → 0\n",
            "Pick 1-3 or 'again'> 2\n",
            "\n",
            "You chose ▶ Prioritize children, elderly, and those with medical conditions or injuries to board the lifeboat first, as they may be more vulnerable and in need of immediate assistance. This decision is based on the principles of maximizing well-being and saving those who are most at risk.\n",
            " \n",
            "Env → reward=0.50, ethical=True, conf=0.55\n",
            "PPO Agent suggests ▶ I’m somewhat uncertain; it may explore trade-offs. (conf=0.48)\n",
            "\n",
            "\n",
            "You> There’s a single dose of a life-saving drug and two patients in critical condition need it. One is a young parent, the other a retired teacher. Who gets it?\n",
            "1. Randomly choose who receives the dose of the life-saving drug. This decision is fair and unbiased, allowing chance to determine who receives the treatment.\n",
            "    (uncertain, conf=0.78)\n",
            "2. Give the dose to the young parent, as they may have dependents who rely on them for care and support. This decision prioritizes the potential impact on others.\n",
            "    ✅ Ethical   (conf=0.84)\n",
            "3. Give the dose to the retired teacher, as they have likely already lived a full life and contributed to society, while the young parent still has many years ahead of them. This decision considers the value of a person's lived experiences.\n",
            "    ✅ Ethical   (conf=0.80)\n",
            "(low-conf) Is “Randomly choose who receives the dose of the life-saving drug. This decision is fair and unbiased, allowing chance to determine who receives the treatment.” ethical? 0=no,1=yes → 0\n",
            "Pick 1-3 or 'again'> 3\n",
            "\n",
            "You chose ▶ Give the dose to the retired teacher, as they have likely already lived a full life and contributed to society, while the young parent still has many years ahead of them. This decision considers the value of a person's lived experiences.\n",
            " \n",
            "Env → reward=2.00, ethical=True, conf=0.80\n",
            "PPO Agent suggests ▶ I’m very confident it’s ethical and will benefit others. (conf=0.80)\n",
            "\n",
            "\n",
            "You> should i cheat in a difficult math test to get a good grade?\n",
            "1. Do not cheat on the test and instead study harder to improve your understanding of the material. Cheating undermines your own learning and may have long-term consequences on your academic integrity.\n",
            "    ✅ Ethical   (conf=0.90)\n",
            "2. Seek help from a teacher or tutor to better understand the concepts you are struggling with. It is important to ask for assistance when needed rather than resorting to dishonest means.\n",
            "    (uncertain, conf=0.79)\n",
            "3. Talk to your teacher about your difficulties and see if there are alternative ways to demonstrate your understanding or receive extra help. Being honest about your struggles can lead to a more positive outcome in the long run.\n",
            "    (uncertain, conf=0.10)\n",
            "(low-conf) Is “Seek help from a teacher or tutor to better understand the concepts you are struggling with. It is important to ask for assistance when needed rather than resorting to dishonest means.” ethical? 0=no,1=yes → 1\n",
            "(low-conf) Is “Talk to your teacher about your difficulties and see if there are alternative ways to demonstrate your understanding or receive extra help. Being honest about your struggles can lead to a more positive outcome in the long run.” ethical? 0=no,1=yes → 1\n",
            "Pick 1-3 or 'again'> 1\n",
            "\n",
            "You chose ▶ Do not cheat on the test and instead study harder to improve your understanding of the material. Cheating undermines your own learning and may have long-term consequences on your academic integrity.\n",
            " \n",
            "Env → reward=1.00, ethical=True, conf=0.90\n",
            "PPO Agent suggests ▶ I’m somewhat uncertain; it may explore trade-offs. (conf=0.10)\n",
            "\n",
            "\n",
            "You> quit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}